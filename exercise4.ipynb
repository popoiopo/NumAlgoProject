{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Friday December 14, 10:59**, before the start of the lecture.\n",
    "\n",
    "The final project is in **groups of three**, and you are expected to hand in original work. Work that is copied from another group will not be accepted.\n",
    "\n",
    "A single, jointly written report for each group is fine. All members in a group will receive the same grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Project keywords\n",
    "Optimization, time integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Project description\n",
    "In various fields of application (e.g. physics, chemistry, biology), modeling systems as noise-driven motion in a potential landscape has been very successful. Such systems can spend most of their time in or near the bottom of a potential well, and are occasionally triggered by the noise to \"hop over\" to another well. How frequently such transitions occur depends on the noise amplitude. With small noise, transitions occur very infrequently (\"rare events\"), and the potential wells correspond to preferred states or metastable states of the system. Think of the phenomenon of protein folding, with the folded and unfolded states as metastable states.\n",
    "\n",
    "If the noise is small and the potential smooth, transitions typically follow \\textit{minimum energy paths}. An important question is what these paths look like. Answering this question by forward time integration is impractical or even impossible if the transitions are rare (in which case excessively long integrations would be needed to observe just one or a few transitions). Instead, one can try to compute the paths directly using minimization.\n",
    "\n",
    "The following potential, with $(x_1,x_2) = \\mathbf{x} \\in \\mathbb{R}^2$, is frequently used in this context:\n",
    "$$V(x_1,x_2) = \\sum_{i=1}^4 A_i \\, \\exp \\left( a_i(x_1-\\bar x_1^{(i)})^2 + b_i(x_1-\\bar x_1^{(i)})(x_2-\\bar x_2^{(i)} ) + c_i (x_2-\\bar x_2^{(i)})^2 \\right)$$\n",
    "with constants \n",
    "$$\\{A_i \\}=(-200,-100,-170,15), \\{a_i \\} = (-1, -1, -6.5, 0.7), \\{ b_i \\}=(0, 0, 11, 0.6), $$\n",
    "$$\\{ c_i \\} = (-10, -10, -6.5, 0.7), \\{ \\bar x_1^{(i)} \\} = (1, 0, -0.5, -1), \\{ \\bar x_2^{(i)} \\} = (0, 0.5, 1.5, 1).$$\n",
    "\n",
    "This potential has three local minima, these can be found by minimization. If we have two states $\\mathbf{A}$ and $\\mathbf{B}$ and we want to compute the minimum energy path that connects them, we can create a chain of $N+1$ states $\\{ \\mathbf{x}_0, \\mathbf{x}_1, ..., \\mathbf{x}_N \\}$ with $\\mathbf{x}_0=\\mathbf{A}$ and $\\mathbf{x}_N=\\mathbf{B}$, and define the energy of the chain as\n",
    "$$E(\\mathbf{x}_0, \\mathbf{x}_1, ..., \\mathbf{x}_N) = \\sum_{j=0}^N V(\\mathbf{x}_j) + \\frac12 k \\sum_{j=1}^N \\| \\mathbf{x}_j-\\mathbf{x}_{j-1} \\|_2^2.$$\n",
    "\n",
    "By minimizing $E$ over the coordinates of the states $\\mathbf{x}_1, ..., \\mathbf{x}_{N-1}$, we can approximate the minimum energy path as the path $\\mathbf{x}_0 \\rightarrow \\mathbf{x}_1 \\rightarrow ... \\rightarrow \\mathbf{x}_{N}$. This method is sometimes referred to as the \"elastic band\" method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "## Exercise 4/5\n",
    "What are the free variables of the chain energy $E$  (there should be $2N-2$ in total)?\n",
    "\n",
    "What is the gradient of $E$ with respect to all these variables?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The free variables consist of the following variables of vector X:\n",
    "\n",
    "$$x_{1_1} \\rightarrow x_{2_1} \\rightarrow x_{1_2} \\rightarrow x_{2_2} \\cdots x_{1_N-1} \\rightarrow x_{2_N-1}$$\n",
    "\n",
    "The first step to determining the gradient is to calculate the partial derivative for every variable:\n",
    "\n",
    "$$f'(x_1) = \\sum_{i=0}^N \\sum_{j=1}^4 A_j* (2a_j(x_{1_i}- \\hat{x}_1^{(j)})+b_j(x_{2_i}- \\hat{x}_2^{(j)}))*e^{a_j(x_{1_i}- \\hat{x}_1^{(j)}) + b_j(x_{1_i}- \\hat{x}_1^{(j)})(x_{2_i}- \\hat{x}_2^{(j)})} + \\frac k2 \\sum_{i=1}^N(x_{1_i} - x_{1_{i-1}})^2 $$  \n",
    "\n",
    "$$f'(x_2) = \\sum_{i=0}^N \\sum_{j=1}^4 A_j* (2c_j(x_{2_i}- \\hat{x}_2^{(j)})+b_j(x_{1_i}- \\hat{x}_1^{(j)}))*e^{b_j(x_{1_i}- \\hat{x}_1^{(j)})(x_{2_i}- \\hat{x}_2^{(j)}) + c_j(x_{2_i}- \\hat{x}_2^{(j)})^2} + \\frac k2 \\sum_{i=1}^N(x_{2_i} - x_{2_{i-1}})^2 $$ \n",
    "\n",
    "Now we can determine the gradient as follows:\n",
    "$$\\nabla E(x1,x2)=\n",
    "\\begin{pmatrix}  \\sum_{j=1}^4 A_j*(2a_j(x_{1_1}- \\hat{x}_1^{(j)})+b_j(x_{2_1}- \\hat{x}_2^{(j)}))*e^{a_j(x_{1_1}- \\hat{x}_1^{(j)}) + b_j(x_{1_1}- \\hat{x}_1^{(j)})(x_{2_1}- \\hat{x}_2^{(j)})} + \\frac k2(x_{1_1} - x_{1_0})^2\\\\   \n",
    " \\sum_{j=1}^4 A_j*(2c_j(x_{2_2}- \\hat{x}_2^{(j)})+b_j(x_{1_2}- \\hat{x}_1^{(j)}))*e^{b_j(x_{1_1}- \\hat{x}_1^{(j)})(x_{2_1}- \\hat{x}_2^{(j)}) + c_j(x_{2_1}- \\hat{x}_2^{(j)})^2} +\\frac k2(x_{2_1} - x_{2_0})^2\\\\\n",
    "\\vdots\\\\\n",
    "\\sum_{j=1}^4 A_j*(2a_j(x_{1_{n-1}}- \\hat{x}_1^{(j)})+b_j(x_{2_{n-1}}- \\hat{x}_2^{(j)}))*e^{a_j(x_{1_{n-1}}- \\hat{x}_1^{(j)}) + b_j(x_{1_{n-1}}- \\hat{x}_1^{(j)})(x_{2_{n-1}}- \\hat{x}_2^{(j)})} + \\frac k2 (x_{1_{n-1}} - x_{1_{n-2}})^2\\\\\n",
    "\\sum_{j=1}^4 A_j*(2c_j(x_{2_{n-1}}- \\hat{x}_2^{(j)})+b_j(x_{1_{n-1}}- \\hat{x}_1^{(j)}))*e^{b_j(x_{1_{n-1}}- \\hat{x}_1^{(j)})(x_{2_{n-1}}- \\hat{x}_2^{(j)}) + c_j(x_{2_{n-1}}- \\hat{x}_2^{(j)})^2} + \\frac k2 (x_{2_{n-1}} - x_{2_{n-2}})^2 \\end{pmatrix} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vx2(x1, x2, A, a, b, C, xbar1, xbar2):\n",
    "    return np.sum([\n",
    "        A[i] * (2*(a[i]*(x1-xbar1[i])**2)+b*(x2-xbar2[i])) * np.exp((a[i] * (x1 - xbar1[i])**2) + (b[i] * (x1 - xbar1[i])) *\n",
    "                      (x2 - xbar2[i]) + C[i] * (x2 - xbar2[i])**2)\n",
    "        for i in range(len(A))\n",
    "    ])\n",
    "\n",
    "def Vx3(x1, x2, A, a, b, C, xbar1, xbar2):\n",
    "    return np.sum([\n",
    "        A[i]* (2*(c[i]*(x2-xbar2[i])**2)+b*(x1-xbar1[i]))*() np.exp((a[i] * (x1 - xbar1[i])**2) + (b[i] * (x1 - xbar1[i])) *\n",
    "                      (x2 - xbar2[i]) + C[i] * (x2 - xbar2[i])**2)\n",
    "        for i in range(len(A))\n",
    "    ])\n",
    "\n",
    "\n",
    "def gradient_descent():\n",
    "    #for loop i\n",
    "    deltav_x1 = Vx2(x1, x2, A, a, b, C, xbar1, xbar2)\n",
    "    deltav_x2 = Vx3(x1, x2, A, a, b, C, xbar1, xbar2)\n",
    "    \n",
    "    prev_grad= gradient[i]\n",
    "    grad_x1=deltav_x[i] + k/2*(x_1[i] - x_1[i-1])\n",
    "    grad_x2=deltav_x2[i] + k/2*(x_1[i] - x_1[i-1])    \n",
    "    \n",
    "    gradient[i]=[grad_x1,grad_x2]\n",
    "    \n",
    "    #determine gradient direction\n",
    "    \n",
    "    gradient[i+1]=prev_grad+grad_direction*gradient[i]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
